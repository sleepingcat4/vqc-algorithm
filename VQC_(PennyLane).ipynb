{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "25nhGc4Qm6uu"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet PennyLane"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.optimize import NesterovMomentumOptimizer"
      ],
      "metadata": {
        "id": "ddkdPWQ7oEVa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev = qml.device(\"default.qubit\", wires=4)"
      ],
      "metadata": {
        "id": "z5EDbtqXoIQV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def layer(W):\n",
        "\n",
        "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0)\n",
        "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
        "    qml.Rot(W[2, 0], W[2, 1], W[2, 2], wires=2)\n",
        "    qml.Rot(W[3, 0], W[3, 1], W[3, 2], wires=3)\n",
        "\n",
        "    qml.CNOT(wires=[0, 1])\n",
        "    qml.CNOT(wires=[1, 2])\n",
        "    qml.CNOT(wires=[2, 3])\n",
        "    qml.CNOT(wires=[3, 0])"
      ],
      "metadata": {
        "id": "BKKm6BvvoQgG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def statepreparation(x):\n",
        "    qml.BasisState(x, wires=[0, 1, 2, 3])"
      ],
      "metadata": {
        "id": "SBtMx1cko86T"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def circuit(weights, x):\n",
        "\n",
        "    statepreparation(x)\n",
        "\n",
        "    for W in weights:\n",
        "        layer(W)\n",
        "\n",
        "    return qml.expval(qml.PauliZ(0))"
      ],
      "metadata": {
        "id": "PlgfbF3bpHEp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def variational_classifier(weights, bias, x):\n",
        "    return circuit(weights, x) + bias"
      ],
      "metadata": {
        "id": "p0H5zwqUpauZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def square_loss(labels, predictions):\n",
        "    loss = 0\n",
        "    for l, p in zip(labels, predictions):\n",
        "        loss = loss + (l - p) ** 2\n",
        "\n",
        "    loss = loss / len(labels)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "O6FybuwdpcwU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(labels, predictions):\n",
        "\n",
        "    loss = 0\n",
        "    for l, p in zip(labels, predictions):\n",
        "        if abs(l - p) < 1e-5:\n",
        "            loss = loss + 1\n",
        "    loss = loss / len(labels)\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Bb_Z_CejpgTf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cost(weights, bias, X, Y):\n",
        "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
        "    return square_loss(Y, predictions)"
      ],
      "metadata": {
        "id": "z__nXXkApiog"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.loadtxt(\"variational_classifier/data/parity.txt\")\n",
        "X = np.array(data[:, :-1], requires_grad=False)\n",
        "Y = np.array(data[:, -1], requires_grad=False)\n",
        "Y = Y * 2 - np.ones(len(Y))  # shift label from {0, 1} to {-1, 1}\n",
        "\n",
        "for i in range(5):\n",
        "    print(\"X = {}, Y = {: d}\".format(X[i], int(Y[i])))\n",
        "\n",
        "print(\"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaYZ2eGZplqz",
        "outputId": "4676d0eb-a5de-4d87-da5d-dfd903c436c5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X = [0. 0. 0. 0.], Y = -1\n",
            "X = [0. 0. 0. 1.], Y =  1\n",
            "X = [0. 0. 1. 0.], Y =  1\n",
            "X = [0. 0. 1. 1.], Y = -1\n",
            "X = [0. 1. 0. 0.], Y =  1\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "num_qubits = 4\n",
        "num_layers = 2\n",
        "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
        "bias_init = np.array(0.0, requires_grad=True)\n",
        "\n",
        "print(weights_init, bias_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ko1QJxhqSnt",
        "outputId": "1d8348f8-1e33-4d44-a934-f4ab42a3ad86"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 0.01764052  0.00400157  0.00978738]\n",
            "  [ 0.02240893  0.01867558 -0.00977278]\n",
            "  [ 0.00950088 -0.00151357 -0.00103219]\n",
            "  [ 0.00410599  0.00144044  0.01454274]]\n",
            "\n",
            " [[ 0.00761038  0.00121675  0.00443863]\n",
            "  [ 0.00333674  0.01494079 -0.00205158]\n",
            "  [ 0.00313068 -0.00854096 -0.0255299 ]\n",
            "  [ 0.00653619  0.00864436 -0.00742165]]] 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = NesterovMomentumOptimizer(0.5)\n",
        "batch_size = 5"
      ],
      "metadata": {
        "id": "moUCHUp_qV3d"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = weights_init\n",
        "bias = bias_init\n",
        "for it in range(25):\n",
        "\n",
        "    # Update the weights by one optimizer step\n",
        "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
        "    X_batch = X[batch_index]\n",
        "    Y_batch = Y[batch_index]\n",
        "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
        "\n",
        "    # Compute accuracy\n",
        "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
        "    acc = accuracy(Y, predictions)\n",
        "\n",
        "    print(\n",
        "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
        "            it + 1, cost(weights, bias, X, Y), acc\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ridenNwLqYrx",
        "outputId": "e49e9082-d098-41fe-90d9-3b4c59f6c45e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter:     1 | Cost: 3.4355534 | Accuracy: 0.5000000 \n",
            "Iter:     2 | Cost: 1.9717733 | Accuracy: 0.5000000 \n",
            "Iter:     3 | Cost: 1.8182812 | Accuracy: 0.5000000 \n",
            "Iter:     4 | Cost: 1.5042404 | Accuracy: 0.5000000 \n",
            "Iter:     5 | Cost: 1.1477739 | Accuracy: 0.5000000 \n",
            "Iter:     6 | Cost: 1.2734990 | Accuracy: 0.6250000 \n",
            "Iter:     7 | Cost: 0.8290628 | Accuracy: 0.5000000 \n",
            "Iter:     8 | Cost: 0.3226183 | Accuracy: 1.0000000 \n",
            "Iter:     9 | Cost: 0.1436206 | Accuracy: 1.0000000 \n",
            "Iter:    10 | Cost: 0.2982810 | Accuracy: 1.0000000 \n",
            "Iter:    11 | Cost: 0.3064355 | Accuracy: 1.0000000 \n",
            "Iter:    12 | Cost: 0.1682335 | Accuracy: 1.0000000 \n",
            "Iter:    13 | Cost: 0.0892512 | Accuracy: 1.0000000 \n",
            "Iter:    14 | Cost: 0.0381562 | Accuracy: 1.0000000 \n",
            "Iter:    15 | Cost: 0.0170359 | Accuracy: 1.0000000 \n",
            "Iter:    16 | Cost: 0.0109353 | Accuracy: 1.0000000 \n",
            "Iter:    17 | Cost: 0.0108388 | Accuracy: 1.0000000 \n",
            "Iter:    18 | Cost: 0.0139196 | Accuracy: 1.0000000 \n",
            "Iter:    19 | Cost: 0.0123980 | Accuracy: 1.0000000 \n",
            "Iter:    20 | Cost: 0.0085416 | Accuracy: 1.0000000 \n",
            "Iter:    21 | Cost: 0.0053549 | Accuracy: 1.0000000 \n",
            "Iter:    22 | Cost: 0.0065759 | Accuracy: 1.0000000 \n",
            "Iter:    23 | Cost: 0.0024883 | Accuracy: 1.0000000 \n",
            "Iter:    24 | Cost: 0.0029102 | Accuracy: 1.0000000 \n",
            "Iter:    25 | Cost: 0.0023471 | Accuracy: 1.0000000 \n"
          ]
        }
      ]
    }
  ]
}